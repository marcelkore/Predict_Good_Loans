{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Predict Loan Defaulters Part 2_Pre-Processing</h2>\n",
    "We will be processing this notebook using the insight we gained from the first notebook (link below). <br>\n",
    "[Predict Loan Defaulters: Part 1 - EDA](Link here) \n",
    "\n",
    "I will be running the pipelines one by one for the purpose of going through the different steps invoveld in processing this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Notebook Setup</h3>\n",
    "\n",
    "<ol>\n",
    "  <li>Create Transformers to handle diffrents processing needs of our dataset </li>\n",
    "  <li>Apply Transformation to train and test data</li>\n",
    "</ol> \n",
    "\n",
    "\n",
    "[Github Link to orginial notebooks and helper files](https://github.com/marcelkore/LendingClub_LoanDefaulters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps in the process\n",
    "1. [Reading the DataSet](#reading_the_data)\n",
    "2. [Encode Target Feature](#encode_target)\n",
    "3. [Drop Data Leakage Features](#drop_data_leak)\n",
    "3. [Drop Duplicates](#drop_duplicates)  \n",
    "3. [Drop Single Unique Features](#single_unique)  \n",
    "3. [Handle Missing - Drop Using Threshold](#missing_features)  \n",
    "3. [Impute Categoricals](#impute_categorical)  \n",
    "3. [Impute Numerical](#impute_numerical)  \n",
    "3. [Feature Extraction](#feature_extraction)  \n",
    "3. [Feature Engineering](#feature_engineer)\n",
    "3. [Feature Selection](#feature_selector)\n",
    "3. [Export DataSet](#export_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Standard Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# category encoding\n",
    "import category_encoders as ce\n",
    "\n",
    "#helper functions\n",
    "import helper_functions as helpers\n",
    "import modeling_helper_functions as mhf\n",
    "import parameter_tuning_helper as pt\n",
    "\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "#skearn libraries\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "#from sklearn.preprocessing import Imputer, LabelEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (roc_curve, precision_recall_curve)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from fancyimpute import IterativeImputer\n",
    "\n",
    "from xverse.transformer import WOE\n",
    "\n",
    "import yagmail\n",
    "from missingpy import MissForest\n",
    "\n",
    "import itertools\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# Viz Libraries\n",
    "import seaborn as sns\n",
    "import psutil\n",
    "import matplotlib.style as style\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track how long notebook took to run\n",
    "notebook_start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt\n",
    "#! pipreqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty print all cell's output and not just the last one\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# scientific notation\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not advised but for the ease of running multiple iterations of this notebook, \n",
    "# i set a couple of global variables for use in the subsequent functions\n",
    "CPU_COUNT = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "<h5> We will load the data dictionary to help us inspect feature definitions </h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use data from 2016 and 2017 for training and 2014 and 2018 for test data. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Shape: (877986, 152)\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "train_set = pd.read_csv('lc_2016_2017.csv')\n",
    "\n",
    "# load 2018 data\n",
    "test_set_2018 = pd.read_csv('lc_2018.csv') # 2019\n",
    "\n",
    "# load 2019 data\n",
    "test_set_2019 = pd.read_csv('lc_2019.csv') # 2019\n",
    "\n",
    "# confirm\n",
    "print(\"Train Set Shape: {}\".format(train_set.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Convert DataTypes**\n",
    "<a id=\"encode_target\"></a>\n",
    "<p> For memory management, this first transformer converts 'object' datatypes to the less memory demanding 'category' data types. <br>\n",
    "    We also convert any 'float64' data types to 'float32' <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertDataTypes(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"\n",
    "    This transformer receives a dataframe and performs the following conversion:\n",
    "    \n",
    "    Any 'object' datatypes present are converted to 'category' datatype\n",
    "    Any 'float64' datatypes present are covnerted to 'float32' datatype\n",
    "    \n",
    "    Args: Pass a dataframe\n",
    "    \n",
    "    Returns: \n",
    "    A dataframe with the data types converted\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df): # pass the dataframe\n",
    "        '''\n",
    "        This transformer calls the convert_data_type function from the helpers_functions file. \n",
    "        '''\n",
    "        \n",
    "        df = helpers.convert_data_type(df)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size: (877986, 152)\n"
     ]
    }
   ],
   "source": [
    "# create transformer \n",
    "data_type_encoder = ConvertDataTypes()\n",
    "\n",
    "#fit transform dataset\n",
    "train_set = data_type_encoder.fit_transform(train_set)\n",
    "\n",
    "#fit transform dataset\n",
    "test_set_2018 = data_type_encoder.fit_transform(test_set_2018)\n",
    "test_set_2019 = data_type_encoder.fit_transform(test_set_2019)\n",
    "\n",
    "# confirm\n",
    "print(\"Train Set Size: {}\".format(train_set.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Encode Target Feature**\n",
    "<a id=\"encode_target\"></a>\n",
    "<p> The first step is to split the data into training and test. Since we have an imbalanced dataset as observed in the EDA portion,  <br>\n",
    "    we would be better served if we split it based on having equal representation of our target class in both splits. A stratified split would <br>\n",
    "    be suitable for this although it requires the target feature to be numeric , and hence this first step of encoding our target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x187.2 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# review our target feature distribution\n",
    "sns.catplot(y=\"loan_status\", kind=\"count\", data=train_set, height=2.6, aspect=4.5, orient='h')\n",
    "plt.title('Train Set')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessTargetFeature(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"\n",
    "    This transformer encodes the target feature\n",
    "    \n",
    "    Args: Pass a dataframe\n",
    "    \n",
    "    Returns: \n",
    "    A dataframe with target feature and datatypes converted    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df): # pass the dataframe\n",
    "        \"\"\"\n",
    "        This function calls the helper_functions file to perform the following\n",
    "        \n",
    "        Encode target feature\n",
    "        Filter dataset to the two classes below:\n",
    "        Class 1: Fully Paid Examples in the dataset\n",
    "        Class 0: Charged off, late and defaulted examples.\n",
    "\n",
    "        The target feature is also converted to a category data type\n",
    "        \"\"\"\n",
    "        dataframe = helpers.encode_target_feature(df)\n",
    "                \n",
    "        return dataframe      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size: (482074, 152)\n"
     ]
    }
   ],
   "source": [
    "# create transformer \n",
    "target_encoder = ProcessTargetFeature()\n",
    "\n",
    "#fit transform train and test sets\n",
    "train_set = target_encoder.fit_transform(train_set)\n",
    "\n",
    "#fit transform dataset\n",
    "test_set_2018 = target_encoder.fit_transform(test_set_2018)\n",
    "test_set_2019 = target_encoder.fit_transform(test_set_2019)\n",
    "\n",
    "# confirm\n",
    "print(\"Train Set Size: {}\".format(train_set.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x187.2 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# review new distribution of our target feature\n",
    "sns.catplot(y=\"loan_status\", kind=\"count\", data=test_set_2018, height=2.6, aspect=4.5, orient='h')\n",
    "plt.title('Train Set')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x187.2 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# review new distribution of our target feature\n",
    "sns.catplot(y=\"loan_status\", kind=\"count\", data=train_set, height=2.6, aspect=4.5, orient='h')\n",
    "plt.title('2018 Train Set')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x187.2 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# review new distribution of our target feature\n",
    "sns.catplot(y=\"loan_status\", kind=\"count\", data=test_set_2019, height=2.6, aspect=4.5, orient='h')\n",
    "plt.title('2019 Train Set')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1   0.77\n",
       "0   0.23\n",
       "Name: loan_status, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view percentage distribution\n",
    "train_set.loan_status.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b> Pre-Process Transformers <b></h2>\n",
    "<a id=\"transformers\"></a>\n",
    "We will start our feature selection process during the cleaning phase. With the large number of features available in this dataset,<br> we will first target low hanging fruit i.e., features with a large % of Missing Values, low variance features as candidates for dropping. <p> \n",
    "    \n",
    "<p> We will also drop features as we proceed based on domain/common knowledge i.e., index columns,customer name columns <br>and data collected after a loan applicant has been approved i.e.Target Leak candidates </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b> Drop Features <b></h2>\n",
    "<a id=\"drop_features\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a `transformer` that will handle dropping of the following features in our dataset\n",
    "\n",
    "* Irrelevant features that will not inform our final model i.e, indexes\n",
    "* Data Leakage features (see below)\n",
    "* Other features that we determine are not required\n",
    "\n",
    "<p> Data Leakage has to do with using features collected after our event of interest ..in this case, defaulting on a loan.<br>\n",
    "    To put it in another way, these features will not be available to you prior to making the decision whether you should give an <br>\n",
    "    individual a loan or not. The business has to make a decision prior with all the features that make it to our final model\n",
    "    \n",
    "More details on the link below.\n",
    "</p>  \n",
    "<p> <a href=\"https://machinelearningmastery.com/data-leakage-machine-learning/\">Data Leakage in Machine Learning</a></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropFeatures(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"\n",
    "    This transformer drops features passed in a list and returns\n",
    "    a dataframe with the features dropped.\n",
    "    \n",
    "    Args:\n",
    "    A list of feature names to be dropped and the dataframe object\n",
    "    Returns:\n",
    "    A dataframe with the features provided dropped. \n",
    "    \"\"\"\n",
    "       \n",
    "    def __init__(self,drop_candidates): # pass list of features to be dropped\n",
    "        self.to_drop = drop_candidates\n",
    "        pass\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df):\n",
    "               \n",
    "        drop_features = []\n",
    "        for value in self.to_drop:\n",
    "            if value in df.columns:\n",
    "                drop_features.append(value)\n",
    "                \n",
    "        # Drop the features selected above passed in drop_candidates\n",
    "        return df.drop(labels=drop_features,axis=1) # return dataframe with dropped features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below is a list of features i have determined to either be target leak features or features\n",
    "# that will not inform our model\n",
    "leakage_not_required_features=['recoveries','collection_recovery_fee','last_pymnt_amnt','total_rec_prncp','title',\\\n",
    "                    'total_rec_int','total_rec_late_fee','last_pymnt_d','total_pymnt','funded_amnt',\\\n",
    "                      'total_pymnt_inv','last_credit_pull_d','issue_d','funded_amnt_inv','debt_settlement_flag',\\\n",
    "                'id','member_id','addr_state','zip_code','emp_title','payment_plan_start_date',\n",
    "                'last_fico_range_low','last_fico_range_high','url','issue_date', 'disbursement_method',\\\n",
    "                'desc', 'next_pymnt_d', 'orig_projected_additional_accrued_interest','next_pymnt_d']\n",
    "\n",
    "\n",
    "# we are not going to know payment plan features before providing a loan decision, hence we drop them\n",
    "payment_plan_features = [x for x in train_set.columns[train_set.columns.str.contains('payment')]]\n",
    "\n",
    "# we are not going to know settlement features before providing a loan decision, hence we drop them\n",
    "settlement_features = [x for x in train_set.columns[train_set.columns.str.contains('settlement')]]\n",
    "\n",
    "# hardship features are included if an individual starts facing difficulties during the \n",
    "# life of the loan. definetly information we will not have. hence we drop them\n",
    "hardship_features = [x for x in train_set.columns[train_set.columns.str.contains('hardship')]]\n",
    "\n",
    "# we combine the list of all the features identified above into one list\n",
    "features_to_drop = leakage_not_required_features + payment_plan_features + settlement_features + hardship_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features to be dropped including target leakeage features: 51\n",
      "\n",
      "Number of Payment plan features to be dropped: 2\n",
      "\n",
      "Number of Settlement features to be dropped: 2\n",
      "\n",
      "Number of Hardship features to be dropped: 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features to be dropped including target leakeage features: {}\".format(len(features_to_drop)))\n",
    "print(\"\")\n",
    "\n",
    "# drop_features\n",
    "print(\"Number of Payment plan features to be dropped: {}\".format(len(payment_plan_features)))\n",
    "print(\"\")\n",
    "print(\"Number of Settlement features to be dropped: {}\".format(len(payment_plan_features)))\n",
    "print(\"\")\n",
    "print(\"Number of Hardship features to be dropped: {}\".format(len(hardship_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size: (482074, 105)\n"
     ]
    }
   ],
   "source": [
    "#create transformer\n",
    "drop_features_transformer = DropFeatures(features_to_drop)\n",
    "\n",
    "# fit transform training set\n",
    "train_set = drop_features_transformer.fit_transform(train_set)\n",
    "\n",
    "#fit transform dataset\n",
    "test_set_2018 = drop_features_transformer.fit_transform(test_set_2018)\n",
    "test_set_2019 = drop_features_transformer.fit_transform(test_set_2019)\n",
    "\n",
    "# confirm\n",
    "print(\"Train Set Size: {}\".format(train_set.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b> Drop Joint Applications <b></h2>\n",
    "<a id=\"drop_joint_applications\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Individual   0.96\n",
       "Joint App    0.04\n",
       "Name: application_type, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check application type unique counts\n",
    "train_set.application_type.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x187.2 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# review new distribution of our application types\n",
    "sns.catplot(y=\"application_type\", kind=\"count\", data=train_set, height=2.6, aspect=4.5, orient='h')\n",
    "plt.title('Train Set')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x187.2 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# review new distribution of our application types\n",
    "sns.catplot(y=\"application_type\", kind=\"count\", data=test_set_2018, height=2.6, aspect=4.5, orient='h')\n",
    "plt.title('2018 Test Set')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x187.2 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# review new distribution of our application types\n",
    "sns.catplot(y=\"application_type\", kind=\"count\", data=test_set_2019, height=2.6, aspect=4.5, orient='h')\n",
    "plt.title('2019 Test Set')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The output above shows that we have more examples of individual vs joint applications. We want to avoid imbalanced <br> features and more importantly, we can drop 17+ features related to joint applicants that will be otherwise missing. <br>\n",
    "Let's drop those observations and any joint application features available in the dataset i.e., joint & secondary applicant\n",
    "references <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropJointApplications(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"\n",
    "    This transformer drops feature names that match our strings of interest. \n",
    "    In our case, any references to sec & joint\n",
    "    \n",
    "    Args: \n",
    "    ---------------------------------------------\n",
    "    A datframe with our features\n",
    "    \n",
    "    Returns:\n",
    "    ---------------------------------------------\n",
    "    A dataframe without any features with references\n",
    "    to sec, join, hardship and settlement   \n",
    "    \n",
    "    \"\"\"\n",
    "       \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df):\n",
    "        # we can now assume all references to a secondary applicant start with sec\n",
    "        self.secondary_applicant_drop = [x for x in df.columns[df.columns.str.match('sec')]]\n",
    "        # retrieve columns that contain the word joint which is similar to the\n",
    "        self.secondary_applicant_drop_joint = [x for x in df.columns[df.columns.str.contains('joint')]]\n",
    "   \n",
    "        # Lets drop those features\n",
    "        df.drop(labels=self.secondary_applicant_drop + self.secondary_applicant_drop_joint,inplace=True,axis=1)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size: (482074, 89)\n"
     ]
    }
   ],
   "source": [
    "#create transformer\n",
    "drop_joint_applications_transformer = DropJointApplications()\n",
    "\n",
    "# fit transform training set\n",
    "train_set = drop_joint_applications_transformer.fit_transform(train_set)\n",
    "\n",
    "#fit transform dataset\n",
    "test_set_2018 = drop_joint_applications_transformer.fit_transform(test_set_2018)\n",
    "test_set_2019 = drop_joint_applications_transformer.fit_transform(test_set_2019)\n",
    "\n",
    "# confirm\n",
    "print(\"Train Set Size: {}\".format(train_set.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b> Drop Duplicates <b></h2>\n",
    "<a id=\"drop_duplicates\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicate values decrease the performance of some models. We will drop duplicate observations in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropDuplicates(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"\n",
    "    This transformer drops duplicate observations in the dataset\n",
    "    \n",
    "    Args:\n",
    "    a dataframe\n",
    "    \n",
    "    Returns:\n",
    "    a datframe with all duplicates observations dropped\n",
    "    \n",
    "    \"\"\"\n",
    "       \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df):\n",
    "        # use the pandas function drop duplicates\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size: (482074, 89)\n"
     ]
    }
   ],
   "source": [
    "#create transformer\n",
    "drop_duplicates = DropDuplicates()\n",
    "\n",
    "# fit transform training set\n",
    "train_set = drop_duplicates.fit_transform(train_set)\n",
    "\n",
    "#fit transform dataset\n",
    "test_set_2018 = drop_duplicates.fit_transform(test_set_2018)\n",
    "test_set_2019 = drop_duplicates.fit_transform(test_set_2019)\n",
    "\n",
    "# confirm\n",
    "print(\"Train Set Size: {}\".format(train_set.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b> Drop Single Unique Features <b></h2>\n",
    "<a id=\"single_unique\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Single unique values do not provide enough variance to benefit a ML algorithm. <p> \n",
    "<p> A feature with all zero would not inform our final model <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LowVarianceTransformer(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"\n",
    "    This transformer drops features with single unique values\n",
    "    \n",
    "    Args:\n",
    "    a dataframe\n",
    "    \n",
    "    Returns:\n",
    "    a dataframe with all features with single unique values\n",
    "    dropped\n",
    "    \n",
    "    \"\"\"\n",
    "       \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df):\n",
    "        \"\"\"\n",
    "        Call function that drops single unique values given a \n",
    "        dataframe\n",
    "        \"\"\"\n",
    "        \n",
    "        df = helpers.drop_low_variance_features(df)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features with single unique values is 2\n",
      "The number of features with single unique values is 3\n",
      "The number of features with single unique values is 6\n",
      "Train Set Size: (482074, 87)\n"
     ]
    }
   ],
   "source": [
    "#create transformer\n",
    "drop_low_variance= LowVarianceTransformer()\n",
    "\n",
    "# fit transform training set\n",
    "train_set = drop_low_variance.fit_transform(train_set)\n",
    "\n",
    "#fit transform dataset\n",
    "test_set_2018 = drop_low_variance.fit_transform(test_set_2018)\n",
    "test_set_2019 = drop_low_variance.fit_transform(test_set_2019)\n",
    "\n",
    "# confirm\n",
    "print(\"Train Set Size: {}\".format(train_set.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 87 columns.\n",
      "There are 31 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mths_since_last_record</td>\n",
       "      <td>386495</td>\n",
       "      <td>80.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mths_since_recent_bc_dlq</td>\n",
       "      <td>362589</td>\n",
       "      <td>75.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mths_since_last_major_derog</td>\n",
       "      <td>342935</td>\n",
       "      <td>71.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mths_since_recent_revol_delinq</td>\n",
       "      <td>311913</td>\n",
       "      <td>64.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mths_since_last_delinq</td>\n",
       "      <td>231963</td>\n",
       "      <td>48.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>il_util</td>\n",
       "      <td>63376</td>\n",
       "      <td>13.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mths_since_recent_inq</td>\n",
       "      <td>44460</td>\n",
       "      <td>9.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>emp_length</td>\n",
       "      <td>32570</td>\n",
       "      <td>6.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>num_tl_120dpd_2m</td>\n",
       "      <td>24174</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mths_since_rcnt_il</td>\n",
       "      <td>12467</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mo_sin_old_il_acct</td>\n",
       "      <td>12417</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bc_util</td>\n",
       "      <td>5940</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>percent_bc_gt_75</td>\n",
       "      <td>5716</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bc_open_to_buy</td>\n",
       "      <td>5685</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mths_since_recent_bc</td>\n",
       "      <td>5355</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>revol_util</td>\n",
       "      <td>359</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dti</td>\n",
       "      <td>235</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>all_util</td>\n",
       "      <td>96</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>open_acc_6m</td>\n",
       "      <td>56</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_cu_tl</td>\n",
       "      <td>56</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>inq_last_12m</td>\n",
       "      <td>56</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>open_il_12m</td>\n",
       "      <td>55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>open_act_il</td>\n",
       "      <td>55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_bal_il</td>\n",
       "      <td>55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>open_il_24m</td>\n",
       "      <td>55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>open_rv_12m</td>\n",
       "      <td>55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>inq_fi</td>\n",
       "      <td>55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max_bal_bc</td>\n",
       "      <td>55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>open_rv_24m</td>\n",
       "      <td>55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg_cur_bal</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>inq_last_6mths</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Missing Values  % of Total Values\n",
       "mths_since_last_record                  386495              80.20\n",
       "mths_since_recent_bc_dlq                362589              75.20\n",
       "mths_since_last_major_derog             342935              71.10\n",
       "mths_since_recent_revol_delinq          311913              64.70\n",
       "mths_since_last_delinq                  231963              48.10\n",
       "il_util                                  63376              13.10\n",
       "mths_since_recent_inq                    44460               9.20\n",
       "emp_length                               32570               6.80\n",
       "num_tl_120dpd_2m                         24174               5.00\n",
       "mths_since_rcnt_il                       12467               2.60\n",
       "mo_sin_old_il_acct                       12417               2.60\n",
       "bc_util                                   5940               1.20\n",
       "percent_bc_gt_75                          5716               1.20\n",
       "bc_open_to_buy                            5685               1.20\n",
       "mths_since_recent_bc                      5355               1.10\n",
       "revol_util                                 359               0.10\n",
       "dti                                        235               0.00\n",
       "all_util                                    96               0.00\n",
       "open_acc_6m                                 56               0.00\n",
       "total_cu_tl                                 56               0.00\n",
       "inq_last_12m                                56               0.00\n",
       "open_il_12m                                 55               0.00\n",
       "open_act_il                                 55               0.00\n",
       "total_bal_il                                55               0.00\n",
       "open_il_24m                                 55               0.00\n",
       "open_rv_12m                                 55               0.00\n",
       "inq_fi                                      55               0.00\n",
       "max_bal_bc                                  55               0.00\n",
       "open_rv_24m                                 55               0.00\n",
       "avg_cur_bal                                  5               0.00\n",
       "inq_last_6mths                               1               0.00"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of features with missing values in the dataset\n",
    "helpers.missing_values_table(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b> Impute Numerical Features <b></h2>\n",
    "<a id=\"impute_numerical\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a `transformer` that will handle imputing numerical features. We will impute specific 'count' features that <br>\n",
    "would be penalized  if replaced with a mean or median. These features are relevant in the sense that having an occurence <br>\n",
    "of them is significant i.e., number of charged_off_accounts. The difference between having 1 or more charged_off_accounts <br>\n",
    "and having none (0) means a lot as the latter signifies a discplined clean record  while the former has shown that they <br>\n",
    "are capable of 'defaulting' on an account. Imputing such features with a mean or a median does not  make any sense as they <br>\n",
    "will 'penalize' the observation uncessarily "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplaceWithValue(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"\n",
    "    This transformer imputes missing  categoricals by replacing them \n",
    "    with the median value.\n",
    "    \n",
    "    Args:\n",
    "    features set: A dataframe\n",
    "    \n",
    "    Returns: \n",
    "    A dataframe with numerical features imputed\n",
    "    \"\"\"\n",
    "    def __init__(self, replace_with_value = None):\n",
    "        self.replace_with_value = replace_with_value\n",
    "        pass\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df):\n",
    "        \"\"\"\n",
    "        Call function that imputes missing values in features\n",
    "        passed with a specific value. In this instance the default\n",
    "        replacement value is 0 \n",
    "        \"\"\"\n",
    "        \n",
    "        features_to_impute = []\n",
    "        \n",
    "        for value in self.replace_with_value:\n",
    "            if value in df.columns:\n",
    "                features_to_impute.append(value)        \n",
    "        \n",
    "        \n",
    "        return helpers.impute_numerical_features(df,features_to_impute=features_to_impute)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code selects features that are 'counts' of observations i.e., months since last derogatory account, number of <br> \n",
    "open accounts etc. <br>\n",
    "\n",
    "We will replace all missing instances with zero instead of a median or mean value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mths_since = [x for x in train_set.columns[train_set.columns.str.match('mths_since')]]\n",
    "inquiries_since = [x for x in train_set.columns[train_set.columns.str.match('inq_')]]\n",
    "mo_since = [x for x in train_set.columns[train_set.columns.str.match('mo_sin')]]\n",
    "number_of_counts = [x for x in train_set.columns[train_set.columns.str.match('num_')]]\n",
    "number_of_open_a = [x for x in train_set.columns[train_set.columns.str.match('open_')]]\n",
    "number_of_open_b = [x for x in train_set.columns[train_set.columns.str.match('acc_now')]]\n",
    "number_of_open_c = [x for x in train_set.columns[train_set.columns.str.match('chargeoff_within')]]\n",
    "number_of_open_d = [x for x in train_set.columns[train_set.columns.str.match('inq_last')]]\n",
    "number_of_open_e = [x for x in train_set.columns[train_set.columns.str.match('mort_')]]\n",
    "\n",
    "# ['num_tl_120dpd_2m',  'acc_now_delinq', 'num_tl_30dpd']\n",
    "                                                                             \n",
    "replace_with_zero = number_of_open_a + number_of_open_b +\\\n",
    "                    number_of_open_c + number_of_open_d +\\\n",
    "                    number_of_open_d + number_of_open_e +\\\n",
    "                    mths_since + number_of_counts +\\\n",
    "                    mo_since + inquiries_since"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'False'\n"
     ]
    }
   ],
   "source": [
    "%%script False\n",
    "# check for features in test_set_2018\n",
    "test_set_2018_ft = set(test_set_2018.columns.tolist())\n",
    "\n",
    "# check for features in test_set_2018\n",
    "test_set_2019_ft = set(test_set_2019.columns.tolist())\n",
    "\n",
    "test_set_b = set(replace_with_zero)\n",
    "\n",
    "# select only feature present in train and test set\n",
    "test_set_2018_features = test_set_2018_ft & test_set_b\n",
    "test_set_2019_features = test_set_2019_ft & test_set_b\n",
    "\n",
    "# final list of features present in both train and test\n",
    "final_list_to_zero = list(test_set_2018_features & test_set_2019_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 features have been imputed with 0 value\n",
      "42 features have been imputed with 0 value\n",
      "40 features have been imputed with 0 value\n",
      "Train Set Size: (482074, 87)\n"
     ]
    }
   ],
   "source": [
    "replace_with_value = ReplaceWithValue(replace_with_zero)\n",
    "\n",
    "# fit transform train set\n",
    "train_set = replace_with_value.fit_transform(train_set)\n",
    "\n",
    "#fit transform dataset\n",
    "test_set_2018 = replace_with_value.fit_transform(test_set_2018)\n",
    "test_set_2019 = replace_with_value.fit_transform(test_set_2019)\n",
    "\n",
    "# confirm\n",
    "print(\"Train Set Size: {}\".format(train_set.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b> Feature Extraction <b></h2>\n",
    "<a id=\"feature_extraction\"></a>\n",
    "\n",
    "`Feature extraction`, not to be confused by `Feature Engineering` or feature selection in my opinion deals with extracting features from the <br>\n",
    "existing features. Feature engineering aims to create new features and dimension reduction techniques come up with completly new features that are <br>\n",
    "representative of the orginial data . <br>\n",
    "<br>\n",
    "We will create the `transformer` below to perform the feature extraction on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtraction(TransformerMixin,BaseEstimator):\n",
    "    \n",
    "    \"\"\"\n",
    "    This transformer takes as input a dataframe and a list of features. It then\n",
    "    strips the strings values and leaves only the numerical values resulting in a numeric feature. \n",
    "    \n",
    "    As a secondary step, it also maintains the category dtype for categorical features. \n",
    "    \n",
    "    Args: a dataframe, list of  features to be extracted\n",
    "    \n",
    "    Returns: a dataframe with features extracted\n",
    "     \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,features_to_extract, convert_to_category): # pass list of features with potential numerical values\n",
    "        self.features = features_to_extract\n",
    "        self.convert_cats = convert_to_category\n",
    "        pass\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df):\n",
    "        # calls a function for the helpers file that extract numerical features from a list passed\n",
    "        return helpers.extract_numerical_features(df,\n",
    "                                                  feature_names_to_extract=self.features,\n",
    "                                                  convert_to_categorical=self.convert_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable for feature extractor - pass features you want to extract numerical\n",
    "features_to_extract = ['term','emp_length','earliest_cr_line']\n",
    "convert_to_categorical_dtype = ['term','emp_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size: (482074, 87)\n"
     ]
    }
   ],
   "source": [
    "#create transformer\n",
    "feature_extractor = FeatureExtraction(features_to_extract,convert_to_category = convert_to_categorical_dtype)\n",
    "\n",
    "# fit transform training set\n",
    "train_set = feature_extractor.fit_transform(train_set)\n",
    "\n",
    "#fit transform dataset\n",
    "test_set_2018 = feature_extractor.fit_transform(test_set_2018)\n",
    "test_set_2019 = feature_extractor.fit_transform(test_set_2019)\n",
    "\n",
    "# confirm\n",
    "print(\"Train Set Size: {}\".format(train_set.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b> Handle Missing Values - Drop Using Threshold <b></h2>\n",
    "<a id=\"missing_features\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a `transformer` that will handle dropping of features with missing values and scenarios where imputation should work. This transformer uses a threshold of 80%. We will still inspect <br>\n",
    "the selected features to be dropped to determine if any of them are informative enough for techniques like binning or transforming them into  binary categories. <br>\n",
    "\n",
    "Missing values should be investigated during the exploratory phase to determine why the values are missing and if so, what steps can be taken upstream to ensure they come down the pipeline <br>\n",
    "in a desired format. Organizations with mature data governance shops might see less of these types of issues. <br>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropMissingTransformer(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"\n",
    "    This transformer drops features with greater than 80% of features missing.  \n",
    "    \n",
    "    Args:\n",
    "    features set: A dataframe\n",
    "    drop threshold: optional field with the target % features to be dropped. default is 80\n",
    "    \n",
    "    Returns: \n",
    "    A dataframe without features with greater than the specified amount of missing values\n",
    "    \"\"\"\n",
    "    def __init__(self,drop_threshold = 80):\n",
    "        self.threshold_for_drop = drop_threshold\n",
    "        pass\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df):\n",
    "        # this function calls the helpers - drop_features_with miss function\n",
    "        return helpers.drop_features_with_missing_values(df,threshold_value=self.threshold_for_drop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size: (482074, 87)\n"
     ]
    }
   ],
   "source": [
    "#create transformer\n",
    "drop_missing= DropMissingTransformer()\n",
    "\n",
    "# fit transform training set\n",
    "train_set = drop_missing.fit_transform(train_set)\n",
    "\n",
    "#fit transform dataset\n",
    "test_set_2018 = drop_missing.fit_transform(test_set_2018)\n",
    "test_set_2019 = drop_missing.fit_transform(test_set_2019)\n",
    "\n",
    "# confirm\n",
    "print(\"Train Set Size: {}\".format(train_set.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 87 columns.\n",
      "There are 12 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>il_util</td>\n",
       "      <td>63376</td>\n",
       "      <td>13.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>emp_length</td>\n",
       "      <td>32570</td>\n",
       "      <td>6.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bc_util</td>\n",
       "      <td>5940</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Missing Values  % of Total Values\n",
       "il_util              63376              13.10\n",
       "emp_length           32570               6.80\n",
       "bc_util               5940               1.20"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of features with missing values in the dataset\n",
    "helpers.missing_values_table(train_set).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b> Impute Categorical Features <b></h2>\n",
    "<a id=\"impute_categorical\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a `transformer` that will handle imputing categorical features <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Impute_Categorical_Features(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"\n",
    "    This transformer imputes missing  categoricals by replacing them \n",
    "    with the most frequent occurence in the feature. It uses the sklearn_pandas\n",
    "    library and replaces missing values with the most frequent occurence\n",
    "    \n",
    "    It will determine categorical features using the dtype 'category'\n",
    "    \n",
    "    Args:\n",
    "    features set: A dataframe\n",
    "    \n",
    "    Returns: \n",
    "    A dataframe with categorical features imputed\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df):\n",
    "        '''\n",
    "        create a list of categorical features by identifying\n",
    "        them using the dtype ='category'\n",
    "        '''\n",
    "        df = helpers.impute_features(df,strategy='most_frequent')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size: (482074, 87)\n"
     ]
    }
   ],
   "source": [
    "#create transformer\n",
    "cat_imputer = Impute_Categorical_Features()\n",
    "\n",
    "# fit transform training set\n",
    "train_set = cat_imputer.fit_transform(train_set)\n",
    "\n",
    "#fit transform dataset\n",
    "test_set_2018 = cat_imputer.fit_transform(test_set_2018)\n",
    "test_set_2019 = cat_imputer.fit_transform(test_set_2019)\n",
    "\n",
    "# confirm\n",
    "print(\"Train Set Size: {}\".format(train_set.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <b> Category Encoding </b> </h2>\n",
    "<a id=\"category_encoder\"></a>\n",
    "\n",
    "`Categorical Data`, as the name suggests refers to data that is grouped into different categories such that each variable can take on a limited, or typically <br>\n",
    "fixed number of possible values, thus assigning each individual to a particular category. <br>\n",
    "\n",
    "Different types of categorical data exist today in literature. \n",
    "\n",
    "`Nominal Data` - Defines categorical data without any natural order i.e., dataset that has favourite pie as a feature representing different categories (pies) <br>\n",
    "`Ordinal Data` - As the name implies, this is categorical data that has a ranking order i.e., first grade, second grade, third grade <br>\n",
    "\n",
    "In general, how we handle such features slightly varies depending on the algorithms we are planning to use. We will use the category_encoders libarary <br>\n",
    "to perform the encoding of our categorical data. \n",
    "\n",
    "As a note, there are different types of categorical encoding schemes available including `Binary encoding`,  `One Hot Encoding (OHE)` etc. <br>\n",
    "\n",
    "Some literature highlights that tree-based algorithms are not affected by OneHotEncoding while other say they do. See article below. \n",
    "<p> <a href=\"https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests//\">RomanticAnalytics take on OneHotEncoding</a></p>\n",
    "\n",
    "For ordered features, we will use the ordinal encoder to maintain the relationship in heirarchy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ordinal_Encoder(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"\n",
    "    This transformer takes as input a dataframe and encodes\n",
    "    pre-selected features passed as a list.\n",
    "    \n",
    "    Args:\n",
    "    a dataframe and ordinal features\n",
    "    \n",
    "    Returns: \n",
    "    a dataframe containing encoded categorical features\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,strategy,list_of_features):\n",
    "        self.list_of_features = list_of_features\n",
    "        self.strategy = strategy\n",
    "        pass\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df): # pass the dataframe \n",
    "        # catboost ordinal encoder uses the target variable to determine the encodings\n",
    "        dataframe = helpers.encode_categorical_features(df,self.strategy,self.list_of_features)\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>293736</td>\n",
       "      <td>36.00</td>\n",
       "      <td>A</td>\n",
       "      <td>A4</td>\n",
       "      <td>5.00</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>debt_consolidation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>453080</td>\n",
       "      <td>36.00</td>\n",
       "      <td>A</td>\n",
       "      <td>A2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>debt_consolidation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>401229</td>\n",
       "      <td>36.00</td>\n",
       "      <td>B</td>\n",
       "      <td>B4</td>\n",
       "      <td>10.00</td>\n",
       "      <td>OWN</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>credit_card</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term grade sub_grade emp_length home_ownership verification_status  \\\n",
       "293736 36.00     A        A4       5.00       MORTGAGE        Not Verified   \n",
       "453080 36.00     A        A2       1.00       MORTGAGE        Not Verified   \n",
       "401229 36.00     B        B4      10.00            OWN        Not Verified   \n",
       "\n",
       "       loan_status pymnt_plan             purpose  \n",
       "293736           1          n  debt_consolidation  \n",
       "453080           1          n  debt_consolidation  \n",
       "401229           1          n         credit_card  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.iloc[:,0:25].select_dtypes(include='category').sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size: (482074, 87)\n"
     ]
    }
   ],
   "source": [
    "# ordinal features to encode using the ordinal encoder\n",
    "ordinals = ['grade','sub_grade']\n",
    "\n",
    "#create transformer\n",
    "ordinal_encoder =Ordinal_Encoder(strategy='ordinal',list_of_features=ordinals)\n",
    "\n",
    "# fit transform training set\n",
    "train_set = ordinal_encoder.fit_transform(train_set)\n",
    "\n",
    "#fit transform dataset\n",
    "test_set_2018 = ordinal_encoder.fit_transform(test_set_2018)\n",
    "test_set_2019 = ordinal_encoder.fit_transform(test_set_2019)\n",
    "\n",
    "# confirm\n",
    "print(\"Train Set Size: {}\".format(train_set.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>414451</td>\n",
       "      <td>36.00</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>10.00</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>medical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390790</td>\n",
       "      <td>36.00</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>5.00</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>credit_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320741</td>\n",
       "      <td>36.00</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>6.00</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>credit_card</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term grade sub_grade emp_length home_ownership verification_status  \\\n",
       "414451 36.00     5        21      10.00       MORTGAGE     Source Verified   \n",
       "390790 36.00     3        12       5.00           RENT            Verified   \n",
       "320741 36.00     3        13       6.00       MORTGAGE        Not Verified   \n",
       "\n",
       "       pymnt_plan      purpose  \n",
       "414451          n      medical  \n",
       "390790          n  credit_card  \n",
       "320741          n  credit_card  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.iloc[:,0:25].select_dtypes(include='category').sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Non_Ordinal_Encoder(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"\n",
    "    This transformer takes as input a dataframe and encodes selected features. \n",
    "    \n",
    "    Args: a dataframe\n",
    "    \n",
    "    Returns: \n",
    "    a dataframe containing encoded categorical features. We use the JamesStein Encoder\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,strategy,list_of_features):\n",
    "        self.list_of_features = list_of_features\n",
    "        self.strategy = strategy\n",
    "        pass\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df): # pass the dataframe \n",
    "        # encoder uses the target variable to determine the encodings\n",
    "        # thus we will split the dataset as such, show below\n",
    "        dataframe = helpers.encode_categorical_features(df,self.strategy, self.list_of_features)\n",
    "        return dataframe    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal features to exclude\n",
    "features_to_exclude = ['grade','sub_grade','emp_length','term']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude the features above as the transformer relies on the 'category' data type to single out features for encoding. <br>\n",
    "Loan status is also excluded in the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size: (482074, 87)\n"
     ]
    }
   ],
   "source": [
    "#create transformer\n",
    "non_ordinal_encoder =Non_Ordinal_Encoder(strategy='non_ordinal',list_of_features=features_to_exclude)\n",
    "\n",
    "# fit transform training set\n",
    "train_set = non_ordinal_encoder.fit_transform(train_set)\n",
    "\n",
    "#fit transform dataset\n",
    "test_set_2018 = non_ordinal_encoder.fit_transform(test_set_2018)\n",
    "test_set_2019 = non_ordinal_encoder.fit_transform(test_set_2019)\n",
    "\n",
    "# confirm\n",
    "print(\"Train Set Size: {}\".format(train_set.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>purpose</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>application_type</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>14656</td>\n",
       "      <td>60.00</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>308020</td>\n",
       "      <td>60.00</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term grade sub_grade emp_length home_ownership verification_status  \\\n",
       "14656  60.00     3        14       1.00           0.73                0.77   \n",
       "308020 60.00     3        11       7.00           0.73                0.71   \n",
       "\n",
       "       pymnt_plan purpose initial_list_status application_type loan_status  \n",
       "14656        0.77    0.76                0.78             0.73           1  \n",
       "308020       0.77    0.78                0.78             0.77           0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm categorical features have been encoded and ordinal features excluded\n",
    "train_set.select_dtypes(include='category').sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above, we can now see that all our categorical features have been imputed and encoded based on their specific characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 87 columns.\n",
      "There are 11 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>il_util</td>\n",
       "      <td>63376</td>\n",
       "      <td>13.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bc_util</td>\n",
       "      <td>5940</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>percent_bc_gt_75</td>\n",
       "      <td>5716</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bc_open_to_buy</td>\n",
       "      <td>5685</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>revol_util</td>\n",
       "      <td>359</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dti</td>\n",
       "      <td>235</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>all_util</td>\n",
       "      <td>96</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_cu_tl</td>\n",
       "      <td>56</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_bal_il</td>\n",
       "      <td>55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max_bal_bc</td>\n",
       "      <td>55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg_cur_bal</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Missing Values  % of Total Values\n",
       "il_util                    63376              13.10\n",
       "bc_util                     5940               1.20\n",
       "percent_bc_gt_75            5716               1.20\n",
       "bc_open_to_buy              5685               1.20\n",
       "revol_util                   359               0.10\n",
       "dti                          235               0.00\n",
       "all_util                      96               0.00\n",
       "total_cu_tl                   56               0.00\n",
       "total_bal_il                  55               0.00\n",
       "max_bal_bc                    55               0.00\n",
       "avg_cur_bal                    5               0.00"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of features with missing values in the dataset\n",
    "helpers.missing_values_table(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b> Impute Numerical Features <b></h2>\n",
    "<a id=\"impute_numerical\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a `transformer` that will handle imputing numerical features.<br>\n",
    "I'll be using MICE imputation for the remaining missing numerical values. More on MICE imputation below:\n",
    "\n",
    "[Azure et,al on MICE Imputation](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074241/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Impute_Numerical_Features(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"\n",
    "    This transformer imputes missing numerical using the \n",
    "    Iterative imputer which is a variant of mice imputation. \n",
    "    \n",
    "    Args:\n",
    "    features set: A dataframe\n",
    "    \n",
    "    Returns: \n",
    "    A dataframe with numerical features imputed\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df):\n",
    "              \n",
    "        # drop our target feature\n",
    "        x = df.drop('loan_status', axis=1)\n",
    "        # save our target feature in a y variable\n",
    "        y = df.loan_status\n",
    "        \n",
    "        # store feature names for dataframe\n",
    "        column_names = x.columns\n",
    "                \n",
    "        ## MICE Imputation         \n",
    "        # create mice imputer object\n",
    "        mice_imputer = IterativeImputer()\n",
    "        \n",
    "        # fit_transform dataset        \n",
    "        df_temp_imputed = mice_imputer.fit_transform(x)\n",
    "        \n",
    "        # transform back to a dataframe format        \n",
    "        df_temp_imputed = pd.DataFrame(df_temp_imputed,columns=column_names )\n",
    "                         \n",
    "        # merge back the target variable to the dataframe(df)\n",
    "        df = df_temp_imputed.merge(y, on=y.index)  \n",
    "        \n",
    "        df.drop(\"key_0\", axis=1, inplace=True)\n",
    "              \n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size: (482074, 87)\n"
     ]
    }
   ],
   "source": [
    "#create transformer\n",
    "mice_imputer = Impute_Numerical_Features()\n",
    "\n",
    "# fit transform training set\n",
    "train_set = mice_imputer.fit_transform(train_set)\n",
    "\n",
    "#fit transform dataset\n",
    "test_set_2018 = mice_imputer.fit_transform(test_set_2018)\n",
    "test_set_2019 = mice_imputer.fit_transform(test_set_2019)\n",
    "\n",
    "# confirm\n",
    "print(\"Train Set Size: {}\".format(train_set.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 87 columns.\n",
      "There are 0 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Values, % of Total Values]\n",
       "Index: []"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek at remaining missing values in our dataframe\n",
    "helpers.missing_values_table(train_set).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have cleaned the dataset of missing values based on various strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <b> Feature Engineering <b> </h2>\n",
    "<a id=\"feature_engineer\"></a>\n",
    "<p> Feature Engineering different from feature selection involves generating  new features from the existing data as opposed to say <br>\n",
    "    feature selection which picks and chooses which features to drop based on domain knowledge or unimportance </p>\n",
    "    \n",
    "<p> Feature Engineering is the difference between a great model and a subpar model and usual involves sourcing data from outside <br>\n",
    "    other sources to come up with unique features. We stick to the basics below by interacting with existing features to create new ones </p>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineering_Manual(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"\n",
    "    This transformer generates new features from the existing dataset. \n",
    "    \n",
    "    Parameters:\n",
    "    ------------------\n",
    "    A dataframe object\n",
    "    \n",
    "    Returns:\n",
    "    ------------------\n",
    "    A dataframe object with new features created\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df):\n",
    "        # store features in a separate variable                \n",
    "        cats= ['term','emp_length']\n",
    "        df[cats] = df[cats].astype('float32')\n",
    "        \n",
    "        # age of earliest credit line\n",
    "        current_year = date.today().year\n",
    "        df['earliest_cr_line_length'] = current_year - df['earliest_cr_line']\n",
    "    \n",
    "        # total interest paid\n",
    "        df['fe_interest_paid_monthly'] = (df['int_rate'] / 12) * df['loan_amnt']\n",
    "        \n",
    "        df['fe_interest_paid_term'] = (df['int_rate'] / df['term']) * df['loan_amnt']\n",
    "        \n",
    "        # calculate monthly interest paid\n",
    "        df['fe_monthly_int'] = (df[\"loan_amnt\"]/df[\"term\"]) + (((df[\"int_rate\"]/100)* 12) * df[\"loan_amnt\"])\n",
    "        \n",
    "        # Total Loan Two\n",
    "        df['fe_loan_total']=(df.dti/100)*(df.annual_inc/12)*df.term\n",
    "        \n",
    "        # calculate annual percentage rate\n",
    "        df['fe_apr'] = ((df['int_rate'] / df['loan_amnt']) * 365) * 100\n",
    "        \n",
    "        \n",
    "         # monthly payment \n",
    "        df['fe_monthly_payment'] = df['loan_amnt'] /df['term']\n",
    "        \n",
    "        # monthly_to_income_available\n",
    "        df['fe_mti_avail'] = df['annual_inc'] - (df['fe_monthly_payment'] * 1000)\n",
    "        \n",
    "        # debt repayment monthly\n",
    "        df['fe_monthly_income'] = df['annual_inc'].apply(lambda x: x/12 if x > 0 else -9999)\n",
    "        \n",
    "        df['fe_int_rate + open_acc'] = df['int_rate'] + df['open_acc']\n",
    "        \n",
    "        df['fe_int_rate * loan_amnt'] = df['int_rate'] * df['loan_amnt']\n",
    "\n",
    "        \n",
    "        # fico score - i think lending club already uses fico score to determine the grades\n",
    "        # in any case, if they are highly correlated, we have a transformer will take care of that\n",
    "        # below.I am really trying to get interaction between fico score and other 'key' features\n",
    "        df['fico_score'] = ((df['fico_range_high'] + df['fico_range_low'])/2)\n",
    "        \n",
    "        df['fico_score_neg'] = (df['fico_range_high'] - df['fico_range_low'])\n",
    "        \n",
    "        df['fico_score_neg_dti'] = (df['fico_range_high'] - df['fico_range_low']) * df['dti']\n",
    "        \n",
    "        df['fico_score_neg_term'] = (df['fico_range_high'] - df['fico_range_low']) * df['term']\n",
    "        \n",
    "        \n",
    "        df.drop('fico_range_high',axis=1,inplace=True)\n",
    "        df.drop('fico_range_low',axis=1,inplace=True)\n",
    "        df.drop('earliest_cr_line',axis=1,inplace=True)\n",
    "        \n",
    "        cats= ['term','emp_length']        \n",
    "        df[cats] = df[cats].astype('category')\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size: (482074, 99)\n"
     ]
    }
   ],
   "source": [
    "#create transformer\n",
    "ft_engineering = FeatureEngineering_Manual()\n",
    "\n",
    "# fit transform training set\n",
    "train_set = ft_engineering.fit_transform(train_set)\n",
    "\n",
    "#fit transform dataset\n",
    "test_set_2018 = ft_engineering.fit_transform(test_set_2018)\n",
    "test_set_2019 = ft_engineering.fit_transform(test_set_2019)\n",
    "\n",
    "# confirm\n",
    "print(\"Train Set Size: {}\".format(train_set.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <b>Correlation <b> </h2>\n",
    "<a id=\"correlation\"></a>\n",
    "<p> We look for highly correlated features because of a couple of reasons. If two or more features are correlated, they <br>\n",
    "    would be informing our final model with the same information. With a dataset with high dimensions like the one we have, <br>\n",
    "    we are looking for ways of reducing the search space for training our final model. Removing highly correlated features is one way to achieve this</p>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrelationTransformer(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"\n",
    "    This transformer takes as input a dataframe and calculates the correlation between the features. \n",
    "    It will then remove the most correlated features based on a threshold of 0.90\n",
    "    \n",
    "    Args: dataframe and threshold hold value that is defaulted at 0.90\n",
    "    \n",
    "    Return: dataframe with correlated features dropped\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,threshold=0.90):\n",
    "        self.threshold = threshold\n",
    "        pass\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df):\n",
    "        \n",
    "        df = helpers.drop_highly_correlated_features(df)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>disbursement_method</td>\n",
       "      <td>The method by which the borrower receives their loan. Possible values are: CASH, DIRECT_PAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature  \\\n",
       "143  disbursement_method   \n",
       "\n",
       "                                                                                     Description  \n",
       "143  The method by which the borrower receives their loan. Possible values are: CASH, DIRECT_PAY  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helpers.data_dictionary(['disbursement_method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correlated features dropped = 16\n",
      "Train Set Size: (482074, 83)\n"
     ]
    }
   ],
   "source": [
    "#create transformer\n",
    "correlation = CorrelationTransformer()\n",
    "\n",
    "list_of_features_prior = train_set.columns.tolist()\n",
    "\n",
    "# fit transform training set\n",
    "train_set = correlation.fit_transform(train_set)\n",
    "\n",
    "\n",
    "list_of_features_post = train_set.columns.tolist()\n",
    "\n",
    "\n",
    "def Diff(li1, li2): \n",
    "    return (list(set(li1) - set(li2)))\n",
    "\n",
    "corr_features_to_drop = Diff(list_of_features_prior,list_of_features_post )\n",
    "\n",
    "#fit transform dataset\n",
    "\n",
    "for value in corr_features_to_drop:\n",
    "    if value in corr_features_to_drop:\n",
    "        test_set_2018.drop(labels=value,axis=1,inplace=True)\n",
    "        \n",
    "for value in corr_features_to_drop:\n",
    "    if value in corr_features_to_drop:\n",
    "        test_set_2019.drop(labels=value,axis=1,inplace=True)\n",
    "\n",
    "# confirm\n",
    "print(\"Train Set Size: {}\".format(train_set.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see most of our engineered features were dropped since they were highly correlated as suspected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <b> Remove Outliers<b> </h2>\n",
    "<h3> Multi-variate Outlier Detection </h3>\n",
    "<a id=\"outliers\"></a>\n",
    "<p>\n",
    "Outliers represent a rare occurence in the dataset, an unusual occurence of a distribution or some mistakes in the data collection phase. <br>\n",
    "Due to the high dimensions in the dataset, we will employ multi-variate outlier detection techniques. One point to note  is that fact that tree-based algorithms <br>\n",
    "are not neccessarily affected by outliers (Arora, 2016). Having said that, we might try to explore linear models during the feature selection phase or even explore a <br>\n",
    "neural network algorithm which might be affected by outliers. Needless to say, removing outliers from the dataset does not neccesarily degrade performance of a <br>\n",
    "decision tree based algorithm other than the fact we are are removing more training examples that could be used by the model </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Elliptic Envelope </h4>\n",
    "\n",
    "`Elliptic Envolope` function tries to figure out the key parameters while assuming the entire dataset is an expression of an underlying multivariate gaussian distribution. <br>\n",
    "It checks the distance of each observation with respect to a grand mean that takes into account all variables in your dataset. (Boschetti and Massaron, 2018) </p>\n",
    "\n",
    "Elliptic envolope function tries to figure out the key parameters while assuming the entire dataset is an expression of an underlying multivariate gaussian <br>\n",
    "distribution. It will spot both univariate and multivariate outliers. <br> \n",
    "\n",
    "For this reason, we will also ensure we scale the features before performing the outlier detection due to the aforemention assumptioned of a gaussian distribution. <br>\n",
    "The function used below scales the features using sklearn's standard scaler before applying the EE function. \n",
    "    \n",
    "Also for this large dataset, it would be tedious to manually use boxplots to determine and drop outliers for each feature. \n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierTransformer(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"\n",
    "    This transformer is responsible for removing outliers in our dataset. \n",
    "    It uses the elliptical envolope functions to achieve this. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,contamination = 0.2):\n",
    "        self.contamination_value = contamination\n",
    "        pass\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df):\n",
    "        # call the Ellliptic Envelope function through the helpers file\n",
    "        df = helpers.remove_outliers(df)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ramhiser.com/post/2018-03-25-feature-selection-with-scikit-learn-pipeline/\n",
    "class PipelineRFE(Pipeline):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        super(PipelineRFE, self).fit(X, y, **fit_params)\n",
    "        self.feature_importances_ = self.steps[-1][-1].feature_importances_\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierTransformer_Scaled(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "       \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,df):\n",
    "        \n",
    "                \n",
    "        # load preprocessing transformers        \n",
    "        outlier_pipeline= PipelineRFE(steps=[\n",
    "            ('scaling_transformer', StandardScaler()),# here we want to scale our features before running our model tuning\n",
    "            ('outlier_detection', OutlierTransformer())]) # here we pass the outlier transformer\n",
    "            \n",
    "        df=outlier_pipeline.fit_transform(df)          \n",
    "                                     \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of outliers in the dataframe passed : (96415, 84)\n",
      "The number of outliers in the dataframe passed : (32882, 83)\n",
      "The number of outliers in the dataframe passed : (8514, 80)\n",
      "Train Set Size: (385659, 83)\n"
     ]
    }
   ],
   "source": [
    "#create transformer\n",
    "outliers = OutlierTransformer()\n",
    "\n",
    "# fit transform training set\n",
    "train_set = outliers.fit_transform(train_set)\n",
    "\n",
    "#fit transform dataset\n",
    "test_set_2018 = outliers.fit_transform(test_set_2018)\n",
    "test_set_2019 = outliers.fit_transform(test_set_2019)\n",
    "\n",
    "# confirm\n",
    "print(\"Train Set Size: {}\".format(train_set.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <b> Feature Selection <b> </h2>\n",
    "    \n",
    "<h3> <b> Weight of Evidence and Information Value<b> </h3>\n",
    "<a id=\"feature_selector\"></a>\n",
    "    \n",
    "I have reviewed a number of papers related to this specific dataset and what I noticed was that while most of them achieve higher scores, <br>\n",
    "they perform no feature selection whatsoever. This is both impracticable and misleading as a trade-off between predictive performance and <br>\n",
    "model interpretability has to be considered. \n",
    "    \n",
    "For this dataset, we will be using WOE and IV to calculate the most informative features in our dataset. <br>\n",
    "\n",
    "<p> <a href=\"https://medium.com/@sundarstyles89/weight-of-evidence-and-information-value-using-python-6f05072e83eb/\">Weight of Evidence Article</a></p>\n",
    "    \n",
    "    \n",
    "We do this as alluded earlier to reduce model complexity and increase model interpretability. An additional benefit raised by Kuhn & Johnson (2019) <br>\n",
    "is that arriving fewer features can reduce the costs of acquiring data or improving the throughput of software predictions. <br>\n",
    "So, instead of this pipeline processing 145 features we maybe we only include in the pipeline 20 features that we know are enough to give us an acceptable outcome. \n",
    "\n",
    "> Reduce the number of predictors as far as possible without compromising predictive performance (Kuhn & Johnson, 2019.) <br>\n",
    "    \n",
    "Other available methods that can be used include:\n",
    "\n",
    "`RFECV ` -This is considered a greedy wrapper method that uses backwards selection to arrive to a smaller set of predictors. The search begins with a all the <br>\n",
    "features included after which through the ranking generated by feature importance, the set of features is reduced. One disadvantage of this technique is that <br>\n",
    "it does not consider important interactions between different features i.e., fico_score and annual_income together might lead to a more accurate prediction. <br>\n",
    "The second disadvantage is that it is more likely to overfit the training data. The third and most salient for me is that it takes a long long time. <br>\n",
    "\n",
    "`Permutation Importance`  - This method determines important features in a dataset by introducing randomized features and measuring the increase in prediction error <br>\n",
    "(sensitivity of the model). If a feature is important for predicting an outcome, then altering or permuting its values results in a significant reduction of the <br>\n",
    " models performance. If no change is observed, then the assumption is made that the feature was not that important to begin with. It can be used in conjunction with selectkbest <br>\n",
    "as a feature selection method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelection(TransformerMixin,BaseEstimator):\n",
    "    \"\"\"\n",
    "    This transformer takes as input a dataframe and determines features\n",
    "    importance using the Weight of Evidence Algorithm. \n",
    "    \n",
    "    Args: \n",
    "    A dataframe\n",
    "    \n",
    "    Return: \n",
    "    A dataframe with ony important features selected based on a threshold. \n",
    "    \n",
    "    \"\"\"\n",
    "       \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,df):\n",
    "        \n",
    "        cat_features = []\n",
    "        for col_name in df.columns:\n",
    "            if(df[col_name].dtype != 'float64'):\n",
    "                if col_name != 'loan_status':\n",
    "                    cat_features.append(col_name)\n",
    "                df[col_name] = df[col_name].astype('int64')\n",
    "                \n",
    "        # drop our target feature\n",
    "        X = df.drop('loan_status', axis=1)\n",
    "        # save our target feature in a y variable\n",
    "        y = df.loan_status\n",
    "        \n",
    "        # create WOE object\n",
    "        clf = WOE()\n",
    "        \n",
    "        # fit the dataset X,y\n",
    "        clf = clf.fit(X, y)\n",
    "        \n",
    "        # extract dataframe with information value metrics\n",
    "        selected_features = clf.iv_df        \n",
    "        selected_features = selected_features.loc[:,['Variable_Name','Information_Value']]\n",
    "        \n",
    "        # filter features by selecting only features greater than 0.1 and less than 0.5\n",
    "        selected_features = selected_features[(selected_features['Information_Value'] > 0.1) & (selected_features['Information_Value'] <= 0.5)]\n",
    "        \n",
    "        # filter final list of features\n",
    "        final_list = list(selected_features['Variable_Name'].values)   \n",
    "        \n",
    "        # filter our original dataframe and select only\n",
    "        df = X[final_list]     \n",
    "        \n",
    "        # merge back the target variable to the dataframe(df)\n",
    "        df = df.merge(y, on=y.index)\n",
    "        \n",
    "        # drop generated index\n",
    "        df.drop(\"key_0\", axis=1, inplace=True)\n",
    "        \n",
    "        self.cat_features = cat_features\n",
    "                                     \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size: (385659, 7)\n",
      "Time elapsed (hh:mm:ss.ms) 0:03:28.895522\n"
     ]
    }
   ],
   "source": [
    "# time how long the conversion takes\n",
    "start_time = datetime.now()\n",
    "\n",
    "#create transformer\n",
    "feature_selector = FeatureSelection()\n",
    "\n",
    "# fit transform training set\n",
    "train_set = feature_selector.fit_transform(train_set)\n",
    "\n",
    "#fit transform dataset\n",
    "test_set_2018 = test_set_2018[train_set.columns.tolist()]\n",
    "test_set_2019 = test_set_2019[train_set.columns.tolist()]\n",
    "\n",
    "# confirm\n",
    "print(\"Train Set Size: {}\".format(train_set.shape))\n",
    "\n",
    "\n",
    "time_elapsed = datetime.now() - start_time\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we were able to reduce our features from 145+ to 7 features. I might try other techniques for feature selection if the selected <br>\n",
    "seven features do not provide an acceptable performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Shape: (385659, 7)\n",
      "Test 2018 Shape: (131526, 7)\n",
      "Test 2019 Shape: (34053, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Set Shape: {}\".format(train_set.shape))\n",
    "print(\"Test 2018 Shape: {}\".format(test_set_2018.shape))\n",
    "print(\"Test 2019 Shape: {}\".format(test_set_2019.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['term', 'emp_length']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selector.cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <b> Export Cleaned Dataset<b> </h2>\n",
    "<a id=\"export_dataset\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'False'\n"
     ]
    }
   ],
   "source": [
    "%%script False\n",
    "train_set.to_csv('lc_train_cleaned.csv',index=False)\n",
    "test_set_2019.to_csv('lc_2019_test_cleaned.csv',index=False)\n",
    "test_set_2018.to_csv('lc_2018_test_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (hh:mm:ss.ms) 14:00:59.323051\n"
     ]
    }
   ],
   "source": [
    "notebook_time_elapsed = datetime.now() - notebook_start_time\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(notebook_time_elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference: \n",
    "Azur, M, Stuart, E, Frangakis, C and Leaf, P (2012) 'Multiple Imputation by Chained Equations: What is it and how does it work?' Available at: doi: 10.1002/mpr.329\n",
    "\n",
    "Arora, H (2016) 'Why are tree-based models robust to outliers' Available at: https://dimensionless.in/tree-based-models-roboust-outliers/ <br>\n",
    "Accessed: December 23rd, 2019\n",
    "\n",
    "Boschetti, A and Massaron, L (2018) 'Python Data Science Essentials.' 3rd Edition. Packt Publishing \n",
    "\n",
    "Kuhn, M and Johnson, K (2019) 'Feature Engineering and Selection: A Practical Approach for Predictive Models'<br>\n",
    "Available at: https://bookdown.org/max/FES/goals-of-feature-selection.html (Accessed: December 12th, 2019) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "name": "Loan_DataSet_Spark",
  "notebookId": 4295954706501391
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
